{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip3 install pandas numpy scikit-learn lightgbm matplotlib duckdb pyarrow seaborn\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "import duckdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, auc, roc_curve, accuracy_score, \n",
    "                             precision_score, recall_score, f1_score, \n",
    "                             precision_recall_curve, roc_auc_score, brier_score_loss)\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "# install pyarrow to work with parquet files\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "random.seed(37)\n",
    "np.random.seed(37)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control panel- User Input required\n",
    "\n",
    "Update root location, input filetype, site_name and confirm that race/ethnicity mapping correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_config():\n",
    "    json_path = os.path.join(\"..\", \"..\", \"config.json\")\n",
    "    \n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as file:\n",
    "            config = json.load(file)\n",
    "        print(\"Loaded configuration from config.json\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Configuration file not found.\",\n",
    "                                \"Please create config.json based on the config_template.\")\n",
    "    \n",
    "    return config\n",
    "# Load the configuration\n",
    "config = load_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the location for your CLIF-2.0 directory\n",
    "root_location = config['clif2_path']\n",
    "# either parquet or csv only\n",
    "filetype = config['filetype']\n",
    "site_name= config['site']\n",
    "\n",
    "race_map = {\n",
    "    'White': 'White',\n",
    "    'Black or African American': 'Black',\n",
    "    'Black or African-American': 'Black',\n",
    "    'Asian': 'Asian',\n",
    "    'Other': 'Others',\n",
    "    'Unknown': 'Others',\n",
    "    'Did Not Encounter': 'Others',\n",
    "    'Refusal': 'Others',\n",
    "    'American Indian or Alaska Native': 'Others',\n",
    "    'Native Hawaiian or Other Pacific Islander': 'Others',\n",
    "    np.nan: 'Others'\n",
    "}\n",
    "\n",
    "ethnicity_map = {\n",
    "    'Non-Hispanic':'Not Hispanic or Latino',\n",
    "    'Hispanic':'Hispanic or Latino',\n",
    "    'Not Hispanic or Latino': 'Not Hispanic or Latino',\n",
    "    'Hispanic or Latino': 'Hispanic or Latino',\n",
    "    'Did Not Encounter': 'Not Hispanic or Latino',\n",
    "    'Refusal': 'Not Hispanic or Latino',\n",
    "    '*Unspecified': 'Not Hispanic or Latino',\n",
    "    np.nan: 'Not Hispanic or Latino'\n",
    "}\n",
    "\n",
    "finetune=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt_filepath = f\"{root_location}/clif_adt.{filetype}\"\n",
    "encounter_filepath = f\"{root_location}/clif_hospitalization.{filetype}\"\n",
    "vitals_filepath = f\"{root_location}/clif_vitals.{filetype}\"\n",
    "labs_filepath = f\"{root_location}/clif_labs.{filetype}\"\n",
    "demog_filepath = f\"{root_location}/clif_patient.{filetype}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath, filetype):\n",
    "    \"\"\"\n",
    "    Read data from file based on file type.\n",
    "    Parameters:\n",
    "        filepath (str): Path to the file.\n",
    "        filetype (str): Type of the file ('csv' or 'parquet').\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    if filetype == 'csv':\n",
    "        return pd.read_csv(filepath)\n",
    "    elif filetype == 'parquet':\n",
    "        table = pq.read_table(filepath)\n",
    "        return table.to_pandas()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please provide either 'csv' or 'parquet'.\")\n",
    "    \n",
    "\n",
    "def generate_facetgrid_histograms(data, category_column, value_column):\n",
    "    \"\"\"\n",
    "    Generate histograms using seaborn's FacetGrid.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): DataFrame containing the data.\n",
    "        category_column (str): Name of the column containing categories.\n",
    "        value_column (str): Name of the column containing values.\n",
    "\n",
    "    Returns:\n",
    "        FacetGrid: Seaborn FacetGrid object containing the generated histograms.\n",
    "    \"\"\"\n",
    "    # Create a FacetGrid\n",
    "    g = sns.FacetGrid(data, col=category_column, col_wrap=6, sharex=False, sharey=False)\n",
    "    g.map(sns.histplot, value_column, bins=30, color='blue', edgecolor='black')\n",
    "\n",
    "    # Set titles and labels\n",
    "    g.set_titles('{col_name}')\n",
    "    g.set_axis_labels(value_column, 'Frequency')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(f'Histograms of {value_column} by {category_column}', fontsize=16)\n",
    "\n",
    "    return g\n",
    "\n",
    "def standardize_datetime(df):\n",
    "    \"\"\"\n",
    "    Ensure that all *_dttm variables are in the correct format.\n",
    "    Convert all datetime columns to a specific precision and remove timezone\n",
    "    Parameters:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            # Here converting to 'datetime64[ns]' for uniformity and removing timezone with 'tz_convert(None)'\n",
    "            df[col] = df[col].dt.tz_convert(None) if df[col].dt.tz is not None else df[col]\n",
    "            # If you need to standardize to UTC and keep the timezone:\n",
    "            # df[col] = df[col].dt.tz_localize('UTC') if df[col].dt.tz is None else df[col].dt.tz_convert('UTC')\n",
    "    return df\n",
    "\n",
    "def get_sql_import(filetype):\n",
    "    if filetype == 'parquet':\n",
    "        return 'read_parquet'\n",
    "    if filetype == 'csv':\n",
    "        return 'read_csv_auto'\n",
    "\n",
    "sql_import = get_sql_import(filetype=filetype)\n",
    "\n",
    "# create output directory\n",
    "output_directory = os.path.join(os.getcwd(), 'output')\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = read_data(adt_filepath, filetype)\n",
    "encounter = read_data(encounter_filepath, filetype)\n",
    "demog = read_data(demog_filepath, filetype)\n",
    "\n",
    "#clif 2 to clif 1\n",
    "location.rename(columns={'hospitalization_id': 'encounter_id'}, inplace=True)\n",
    "encounter.rename(columns={'hospitalization_id': 'encounter_id'}, inplace=True)\n",
    "demog.rename(columns={'hospitalization_id': 'encounter_id','race_category':'race','ethnicity_category':'ethnicity','sex_category':'sex'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICU close to Admission\n",
    "\n",
    "1. Check ICU location_category between admission_dttmtime and 48hr stop from admission\n",
    "2. Check ICU stay at least 24 hr (for ICU - OR - ICU including OR in ICU stay 24hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data=pd.merge(location[['encounter_id','location_category','in_dttm','out_dttm']],\\\n",
    "                  encounter[['patient_id','encounter_id','age_at_admission','discharge_category','admission_dttm']], on=['encounter_id'], how='left')\n",
    "\n",
    "\n",
    "icu_data['in_dttm'] = pd.to_datetime(icu_data['in_dttm'])\n",
    "icu_data['admission_dttm'] = pd.to_datetime(icu_data['admission_dttm'])\n",
    "icu_data['out_dttm'] = pd.to_datetime(icu_data['out_dttm'])\n",
    "\n",
    "#clif2 to 1\n",
    "icu_data.loc[icu_data['location_category'] == 'procedural', 'location_category'] = \"OR\"\n",
    "icu_data['location_category'] = icu_data['location_category'].str.upper()\n",
    "\n",
    "icu_48hr_check = icu_data[\n",
    "    (icu_data['location_category'] == 'ICU') &\n",
    "    (icu_data['in_dttm'] >= icu_data['admission_dttm']) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=48)) &\n",
    "    (icu_data['admission_dttm'].dt.year >= 2020) & (icu_data['admission_dttm'].dt.year <= 2021) & \n",
    "    (icu_data['age_at_admission'] >= 18) & (icu_data['age_at_admission'].notna())\n",
    "]['encounter_id'].unique()\n",
    "\n",
    "print('check len:',len(icu_48hr_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data=icu_data[icu_data['encounter_id'].isin(icu_48hr_check) & (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=72))].reset_index(drop=True)\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm']).reset_index(drop=True)\n",
    "\n",
    "icu_data[\"RANK\"]=icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(\"encounter_id\")[\"in_dttm\"].rank(method=\"first\", ascending=True).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['RANK'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "icu_data=icu_data[icu_data['RANK']>=icu_data['min_icu']].reset_index(drop=True)\n",
    "\n",
    "icu_data.loc[icu_data['location_category'] == 'OR', 'location_category'] = 'ICU'\n",
    "\n",
    "icu_data['group_id'] = (icu_data.groupby('encounter_id')['location_category'].shift() != icu_data['location_category']).astype(int)\n",
    "icu_data['group_id'] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby('encounter_id')['group_id'].cumsum()\n",
    "\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(['patient_id','encounter_id', 'location_category', 'group_id']).agg(\n",
    "    min_in_dttm=('in_dttm', 'min'),\n",
    "    max_out_dttm=('out_dttm', 'max'),\n",
    "    admission_dttm=('admission_dttm', 'first'),\n",
    "    age=('age_at_admission', 'first'),\n",
    "    dispo=('discharge_category', 'first')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['group_id'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "\n",
    "icu_data=icu_data[(icu_data['min_icu']==icu_data['group_id']) &\n",
    "         (icu_data['max_out_dttm']-icu_data['min_in_dttm'] >= pd.Timedelta(hours=24))\n",
    "         ].reset_index(drop=True)\n",
    "\n",
    "\n",
    "icu_data['after_24hr']=icu_data['min_in_dttm'] + pd.Timedelta(hours=24)\n",
    "\n",
    "icu_data=icu_data[['patient_id','encounter_id','min_in_dttm','max_out_dttm','after_24hr','age','dispo']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data=pd.merge(icu_data,\\\n",
    "                  demog, on=['patient_id'], how='left')[['encounter_id','min_in_dttm','after_24hr','max_out_dttm','age','dispo','sex','ethnicity','race']]\n",
    "icu_data=icu_data[~icu_data['sex'].isna()].reset_index(drop=True)\n",
    "icu_data['isfemale']=(icu_data['sex'].str.lower() == 'female').astype(int)\n",
    "icu_data['isdeathdispo'] = (icu_data['dispo'].fillna('Other').str.contains('dead|expired|death|died', case=False, regex=True)).astype(int)\n",
    "\n",
    "icu_data['ethnicity'] = icu_data['ethnicity'].map(ethnicity_map)\n",
    "icu_data['race'] = icu_data['race'].map(race_map)\n",
    "icu_data['ICU_stay_hrs']= (icu_data['max_out_dttm'] - icu_data['min_in_dttm']).dt.total_seconds() / 3600\n",
    "\n",
    "del location,encounter,demog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = con.execute(f'''\n",
    "    SELECT \n",
    "        hospitalization_id encounter_id,\n",
    "        CAST(recorded_dttm AS datetime) AS recorded_dttm,\n",
    "        CAST(vital_value AS float) AS vital_value,\n",
    "        vital_category \n",
    "    FROM \n",
    "        {sql_import}('{vitals_filepath}')\n",
    "    WHERE \n",
    "        vital_category IN ('weight_kg', 'heart_rate', 'sbp', 'dbp', 'temp_c','height_cm') \n",
    "        AND hospitalization_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "vitals=con.execute('''\n",
    "PIVOT vitals\n",
    "ON vital_category\n",
    "USING first(vital_value)\n",
    "GROUP BY encounter_id,recorded_dttm;\n",
    "''').df()\n",
    "\n",
    "vitals['height_meters'] = vitals['height_cm'] / 100\n",
    "\n",
    "# Calculate BMI\n",
    "vitals['bmi'] = vitals['weight_kg'] / (vitals['height_meters'] ** 2)\n",
    "vitals.rename(columns={'heart_rate': 'pulse'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data_agg=pd.merge(icu_data,vitals, on=['encounter_id'], how='left')\n",
    "icu_data_agg= standardize_datetime(icu_data_agg)\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['recorded_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['recorded_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby(['encounter_id']).agg(\n",
    "    min_bmi=('bmi', 'min'),\n",
    "    max_bmi=('bmi', 'max'),\n",
    "    avg_bmi=('bmi', 'mean'),\n",
    "    min_weight_kg=('weight_kg', 'min'),\n",
    "    max_weight_kg=('weight_kg', 'max'),\n",
    "    avg_weight_kg=('weight_kg', 'mean'),\n",
    "    min_pulse=('pulse', 'min'),\n",
    "    max_pulse=('pulse', 'max'),\n",
    "    avg_pulse=('pulse', 'mean'),\n",
    "    min_sbp=('sbp', 'min'),\n",
    "    max_sbp=('sbp', 'max'),\n",
    "    avg_sbp=('sbp', 'mean'),\n",
    "    min_dbp=('dbp', 'min'),\n",
    "    max_dbp=('dbp', 'max'),\n",
    "    avg_dbp=('dbp', 'mean'),\n",
    "    min_temp_c=('temp_c', 'min'),\n",
    "    max_temp_c=('temp_c', 'max'),\n",
    "    avg_temp_c=('temp_c', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')\n",
    "\n",
    "del vitals,icu_data_agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = con.execute(f'''\n",
    "    SELECT \n",
    "        hospitalization_id encounter_id,\n",
    "        CAST(lab_order_dttm AS datetime) AS lab_order_dttm,\n",
    "        TRY_CAST(lab_value AS float) AS lab_value,\n",
    "        lab_category\n",
    "    FROM \n",
    "         {sql_import}('{labs_filepath}')\n",
    "    WHERE \n",
    "        ((lab_category='monocytes_percent'             ) OR\n",
    "        (lab_category='lymphocytes_percent'            ) OR\n",
    "        (lab_category='basophils_percent'              ) OR \n",
    "        (lab_category='neutrophils_percent'            ) OR\n",
    "        (lab_category='albumin'               ) OR\n",
    "        (lab_category='ast'                   ) OR\n",
    "        (lab_category='total_protein'         ) OR\n",
    "        (lab_category='alkaline_phosphatase'  ) OR\n",
    "        (lab_category='bilirubin_total'       ) OR\n",
    "        (lab_category='bilirubin_conjugated'  ) OR\n",
    "        (lab_category='calcium_total'               ) OR\n",
    "        (lab_category='chloride'              ) OR\n",
    "        (lab_category='potassium'             ) OR\n",
    "        (lab_category='sodium'                ) OR\n",
    "        (lab_category='glucose_serum'         ) OR\n",
    "        (lab_category='hemoglobin'            ) OR\n",
    "        (lab_category='platelet_count'        ) OR\n",
    "        (lab_category='wbc'                   ))\n",
    "        AND hospitalization_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "labs=con.execute('''\n",
    "PIVOT labs\n",
    "ON lab_category\n",
    "USING first(lab_value)\n",
    "GROUP BY encounter_id,lab_order_dttm;\n",
    "''').df()\n",
    "\n",
    "labs.rename(columns={'monocytes_percent': 'monocyte',\n",
    "                     'lymphocytes_percent':'lymphocyte',\n",
    "                     'basophils_percent':'basophil',\n",
    "                     'neutrophils_percent':'neutrophil',\n",
    "                     'calcium_total':'calcium'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data_agg=pd.merge(icu_data,labs, on=['encounter_id'], how='left')\n",
    "icu_data_agg= standardize_datetime(icu_data_agg)\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['lab_order_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['lab_order_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "Lab_variables = [\n",
    "   'albumin', 'alkaline_phosphatase',\n",
    "       'ast', 'basophil', 'bilirubin_conjugated', 'bilirubin_total', 'calcium',\n",
    "       'chloride', 'hemoglobin', 'lymphocyte', 'monocyte', 'glucose_serum', \n",
    "       'neutrophil', 'potassium', 'sodium', 'total_protein','platelet_count', \n",
    "       'wbc'\n",
    "]\n",
    "agg_dict = {var: ['min', 'max', 'mean'] for var in Lab_variables}\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby('encounter_id').agg(agg_dict).reset_index()\n",
    "\n",
    "icu_data_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in icu_data_agg.columns.values]\n",
    "\n",
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_col=['isfemale','age', 'min_bmi', 'max_bmi', 'avg_bmi',\n",
    "       'min_weight_kg', 'max_weight_kg', 'avg_weight_kg', 'min_pulse',\n",
    "       'max_pulse', 'avg_pulse', 'min_sbp', 'max_sbp', 'avg_sbp', 'min_dbp',\n",
    "       'max_dbp', 'avg_dbp', 'min_temp_c', 'max_temp_c', 'avg_temp_c',\n",
    "       'albumin_min', 'albumin_max', 'albumin_mean',\n",
    "       'alkaline_phosphatase_min', 'alkaline_phosphatase_max',\n",
    "       'alkaline_phosphatase_mean', 'ast_min', 'ast_max', 'ast_mean',\n",
    "       'basophil_min', 'basophil_max', 'basophil_mean',\n",
    "       'bilirubin_conjugated_min', 'bilirubin_conjugated_max',\n",
    "       'bilirubin_conjugated_mean', 'bilirubin_total_min',\n",
    "       'bilirubin_total_max', 'bilirubin_total_mean', 'calcium_min',\n",
    "       'calcium_max', 'calcium_mean', 'chloride_min', 'chloride_max',\n",
    "       'chloride_mean', 'glucose_serum_min', 'glucose_serum_max',\n",
    "       'glucose_serum_mean', 'hemoglobin_min', 'hemoglobin_max',\n",
    "       'hemoglobin_mean', 'lymphocyte_min', 'lymphocyte_max',\n",
    "       'lymphocyte_mean', 'monocyte_min', 'monocyte_max', 'monocyte_mean',\n",
    "       'neutrophil_min', 'neutrophil_max', 'neutrophil_mean',\n",
    "       'platelet_count_min', 'platelet_count_max', 'platelet_count_mean',\n",
    "       'potassium_min', 'potassium_max', 'potassium_mean', 'sodium_min',\n",
    "       'sodium_max', 'sodium_mean', 'total_protein_min', 'total_protein_max',\n",
    "       'total_protein_mean', 'wbc_min', 'wbc_max', 'wbc_mean']\n",
    "\n",
    "model=lgb.Booster(model_file='../../icu_mortality_model/models/lgbm_model_20240628-092136.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features_split = [\n",
    "    \"age\",\n",
    "    \"min_pulse\",\n",
    "    \"max_pulse\",\n",
    "    \"max_temp_c\",\n",
    "    \"max_sbp\",\n",
    "    \"glucose_serum_min\",\n",
    "    \"avg_temp_c\",\n",
    "    \"sodium_max\",\n",
    "    \"min_dbp\",\n",
    "    \"platelet_count_min\",\n",
    "    \"min_temp_c\",\n",
    "    \"min_sbp\",\n",
    "    \"avg_sbp\",\n",
    "    \"avg_pulse\",\n",
    "    \"wbc_min\",\n",
    "    \"glucose_serum_mean\",\n",
    "    \"alkaline_phosphatase_max\",\n",
    "    \"hemoglobin_min\",\n",
    "    \"ast_max\",\n",
    "    \"avg_dbp\"\n",
    "]\n",
    "data_unstack=icu_data[imp_features_split].unstack().reset_index(name='value').rename(columns={'level_0': 'imp_features_split', 'level_1': 'i'})\n",
    "imp_plot = generate_facetgrid_histograms(data_unstack, 'imp_features_split', 'value')\n",
    "plt.show(imp_plot)\n",
    "\n",
    "icu_data[imp_features_split].describe().reset_index().rename(columns={'index': 'statistic'}).to_csv(f'{output_directory}/imp_features_split_stats_{site_name}.csv',index=False)\n",
    "del data_unstack,imp_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features_gain=['albumin_min',\n",
    " 'min_pulse',\n",
    " 'ast_mean',\n",
    " 'sodium_max',\n",
    " 'age',\n",
    " 'min_dbp',\n",
    " 'min_sbp',\n",
    " 'max_pulse',\n",
    " 'avg_temp_c',\n",
    " 'ast_max',\n",
    " 'max_temp_c',\n",
    " 'max_sbp',\n",
    " 'platelet_count_min',\n",
    " 'min_temp_c',\n",
    " 'glucose_serum_min',\n",
    " 'glucose_serum_max',\n",
    " 'wbc_mean',\n",
    " 'wbc_min',\n",
    " 'albumin_mean',\n",
    " 'glucose_serum_mean']\n",
    "data_unstack=icu_data[imp_features_gain].unstack().reset_index(name='value').rename(columns={'level_0': 'imp_features_gain', 'level_1': 'i'})\n",
    "imp_plot = generate_facetgrid_histograms(data_unstack, 'imp_features_gain', 'value')\n",
    "plt.show(imp_plot)\n",
    "\n",
    "icu_data[imp_features_gain].describe().reset_index().rename(columns={'index': 'statistic'}).to_csv(f'{output_directory}/imp_features_gain_stats_{site_name}.csv',index=False)\n",
    "del data_unstack,imp_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort file export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data.to_csv(f'{output_directory}/mortality_model_test_dataset_DO_NOT_SHARE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = icu_data[model_col]\n",
    "nan_counts = df.isna().sum()  # Number of NaN values\n",
    "total_rows = len(df)          # Total number of rows\n",
    "nan_percentage = (nan_counts / total_rows) * 100\n",
    "\n",
    "nan_percentage_df = pd.DataFrame({\n",
    "    'Column': nan_counts.index,\n",
    "    'NA_Count': nan_counts.values,\n",
    "    'Total_Rows': total_rows,\n",
    "    'NaN_Percentage': nan_percentage.values\n",
    "})\n",
    "\n",
    "nan_percentage_df.to_csv(f'{output_directory}/features_missing_%_{site_name}.csv', index=False)\n",
    "\n",
    "# Clean up\n",
    "del df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=icu_data[model_col]\n",
    "y_test=icu_data['isdeathdispo']\n",
    "\n",
    "y_pred_proba = model.predict(X_test)\n",
    "icu_data['pred_proba'] = y_pred_proba\n",
    "\n",
    "thr=0.208\n",
    "n_bootstraps = 1000\n",
    "rng_seed = 42  \n",
    "\n",
    "def bootstrap_metric(metric_func, y_test, y_pred_proba, thr, n_bootstraps, rng_seed):\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    bootstrapped_scores = []\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n",
    "        if metric_func == roc_auc_score:\n",
    "            score = metric_func(y_test[indices], y_pred_proba[indices])\n",
    "        else:\n",
    "            y_pred_binary = (y_pred_proba >= thr).astype(int)\n",
    "            score = metric_func(y_test[indices], y_pred_binary[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "    \n",
    "\n",
    "    confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "    confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "    \n",
    "    return confidence_lower, confidence_upper\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, (y_pred_proba >= thr).astype(int))\n",
    "recall = recall_score(y_test, (y_pred_proba >= thr).astype(int))\n",
    "precision = precision_score(y_test, (y_pred_proba >= thr).astype(int))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "accuracy_ci = bootstrap_metric(accuracy_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "recall_ci = bootstrap_metric(recall_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "precision_ci = bootstrap_metric(precision_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "roc_auc_ci = bootstrap_metric(roc_auc_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "brier_score_ci = bootstrap_metric(brier_score_loss, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "\n",
    "results_Metric = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Recall', 'Precision', 'ROC AUC', 'Brier Score Loss'],\n",
    "    'Value': [accuracy, recall, precision, roc_auc, brier_score],\n",
    "    'CI Lower': [accuracy_ci[0], recall_ci[0], precision_ci[0], roc_auc_ci[0], brier_score_ci[0]],\n",
    "    'CI Upper': [accuracy_ci[1], recall_ci[1], precision_ci[1], roc_auc_ci[1], brier_score_ci[1]],\n",
    "    'SiteName': [site_name] * 5\n",
    "})\n",
    "\n",
    "results_Metric.to_csv(f'{output_directory}/result_metrics_2_{site_name}.csv', index=False)\n",
    "\n",
    "\n",
    "results_Metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### probablity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df_lgbm = pd.DataFrame({'site_label ':y_test, 'site_proba': y_pred_proba,'Site_name':f\"{site_name}\" })\n",
    "#prob_df_lgbm.to_csv(f'{output_directory}/Model_probabilities_{site_name}.csv',index=False)\n",
    "prob_df_lgbm.head()\n",
    "#do not share this file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fairness test accross 'race', 'ethnicity', 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data, true_col, pred_prob_col, subgroup_cols, thr=0.208):\n",
    "    results = []\n",
    "    total_count = len(data)\n",
    "\n",
    "    for subgroup_col in subgroup_cols:\n",
    "        filtered_data = data.dropna(subset=[subgroup_col])\n",
    "        \n",
    "        for group in filtered_data[subgroup_col].unique():\n",
    "            subgroup_data = filtered_data[filtered_data[subgroup_col] == group]\n",
    "            group_count = len(subgroup_data)\n",
    "            proportion = group_count / total_count\n",
    "\n",
    "            if np.unique(subgroup_data[true_col]).size > 1:  # Check if both classes are present\n",
    "                auc = roc_auc_score(subgroup_data[true_col], subgroup_data[pred_prob_col])\n",
    "                tn, fp, fn, tp = confusion_matrix(subgroup_data[true_col], (subgroup_data[pred_prob_col] > thr).astype(int)).ravel()\n",
    "                ppv = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "                sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "                specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "                npv = tn / (tn + fn) if (tn + fn) != 0 else 0\n",
    "                recall = sensitivity\n",
    "                acc = (tp + tn) / (tp + fn + tn + fp) if (tp + fn + tn + fp) != 0 else 0\n",
    "\n",
    "                result = {\n",
    "                    'Subgroup': subgroup_col, \n",
    "                    'Group': group,\n",
    "                    'TN': tn,\n",
    "                    'TP': tp,\n",
    "                    'FP' :fp,\n",
    "                    'FN': fn,\n",
    "                    'AUC': auc, \n",
    "                    'PPV': ppv, \n",
    "                    'Sensitivity': sensitivity, \n",
    "                    'Specificity': specificity, \n",
    "                    'NPV': npv, \n",
    "                    'Recall': recall, \n",
    "                    'Accuracy': acc, \n",
    "                    'brier_score': brier_score_loss(subgroup_data[true_col], subgroup_data[pred_prob_col]),\n",
    "                    'Group Count': group_count, \n",
    "                    'Total Count': total_count, \n",
    "                    'Proportion': proportion,\n",
    "                    'site_name': f'{site_name}'\n",
    "                }\n",
    "            else:\n",
    "                result = {\n",
    "                    'Subgroup': subgroup_col, \n",
    "                    'Group': group, \n",
    "                     'TN': tn,\n",
    "                    'TP': tp,\n",
    "                    'FP' :fp,\n",
    "                    'FN': fn,\n",
    "                    'AUC': 'Not defined', \n",
    "                    'PPV': 'Not applicable', \n",
    "                    'Sensitivity': 'Not applicable', \n",
    "                    'Specificity': 'Not applicable', \n",
    "                    'NPV': 'Not applicable', \n",
    "                    'Recall': 'Not applicable', \n",
    "                    'Accuracy': 'Not applicable', \n",
    "                    'brier_score': 'Not applicable', \n",
    "                    'Group Count': group_count, \n",
    "                    'Total Count': total_count, \n",
    "                    'Proportion': proportion,\n",
    "                    'site_name': f'{site_name}'\n",
    "                }\n",
    "            \n",
    "            results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Example usage\n",
    "result_df = calculate_metrics(icu_data, 'isdeathdispo', 'pred_proba', ['race', 'ethnicity', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'{output_directory}/fairness_test_{site_name}.csv',index=False)\n",
    "result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Site Thr Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_percentile(target_var, pred_proba):\n",
    "    #thr_list = [0.99,0.97, 0.95,0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10]\n",
    "    thr_list = np.arange(1, 0, -0.01)\n",
    "    col = ['N Percentile', 'Thr Value','TN','FP','FN','TP','Sensitivity','Specificity','PPV', 'NPV' ,'Recall','Accuracy','site_name']\n",
    "    result = pd.DataFrame(columns = col)\n",
    "    i = 0\n",
    "    \n",
    "    for thr in thr_list: \n",
    "        prob = pd.DataFrame()\n",
    "        prob['target_var'] = target_var\n",
    "        prob['pred_proba'] = pred_proba\n",
    "\n",
    "        thr_value = prob['pred_proba'].quantile(thr)\n",
    "        prob['pred_proba_bin'] = np.where(prob['pred_proba'] >= thr_value, 1, 0)\n",
    "        tn,fp,fn,tp = confusion_matrix(prob['target_var'], prob['pred_proba_bin']).ravel()\n",
    "\n",
    "        sensitivity = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        ppv = tp/(tp+fp)\n",
    "        npv = tn/(tn+fn)\n",
    "        recall = tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+fn+tn+fp)\n",
    "        n_prec = 'Top '+ str(np.round((1 - thr) * 100,0))+ \"%\"\n",
    "        result.loc[i] = [n_prec,thr_value,tn,fp,fn,tp,sensitivity,specificity ,ppv,npv, recall, acc,f'{site_name}']\n",
    "        i+=1\n",
    "    return result\n",
    "topn=top_n_percentile(y_test,y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn.to_csv(f'{output_directory}/Top_N_percentile_PPV_{site_name}.csv',index=False)\n",
    "topn.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUSH THR Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Thr Value','TN','FP','FN','TP','Sensitivity','Specificity','PPV', 'NPV' ,'Recall','Accuracy','site_name']\n",
    "result = pd.DataFrame(columns = col)\n",
    "\n",
    "prob = pd.DataFrame()\n",
    "prob['target_var'] = y_test\n",
    "prob['pred_proba'] = y_pred_proba\n",
    "\n",
    "prob['pred_proba_bin'] = np.where(prob['pred_proba'] >= thr, 1, 0)\n",
    "tn,fp,fn,tp = confusion_matrix(prob['target_var'], prob['pred_proba_bin']).ravel()\n",
    "\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "recall = tp/(tp+fn)\n",
    "acc = (tp+tn)/(tp+fn+tn+fp)\n",
    "n_prec = 'Top '+ str((1 - thr))+ \"%\"\n",
    "result.loc[0] = [thr,tn,fp,fn,tp,sensitivity,specificity ,ppv,npv, recall, acc,f'{site_name}']\n",
    "\n",
    "result.to_csv(f'{output_directory}/Top_N_percentile_atRushThr_{site_name}.csv',index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "def create_calibration_data(y_test, y_pred_proba, n_bins=10):\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({'y_test': y_test, 'y_pred_proba': y_pred_proba})\n",
    "    \n",
    "    # Create bins\n",
    "    df['bin'] = pd.cut(df['y_pred_proba'], bins=n_bins, labels=False, include_lowest=True)\n",
    "    \n",
    "    # Calculate mean predicted probability and actual probability in each bin\n",
    "    calibration_data = df.groupby('bin').agg(\n",
    "        predicted_prob=('y_pred_proba', 'mean'),\n",
    "        actual_prob=('y_test', 'mean'),\n",
    "        n=('y_test', 'size')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate standard error and confidence intervals\n",
    "    calibration_data['se'] = np.sqrt((calibration_data['actual_prob'] * (1 - calibration_data['actual_prob'])) / calibration_data['n'])\n",
    "    calibration_data['lower_ci'] = calibration_data['actual_prob'] - 1.96 * calibration_data['se']\n",
    "    calibration_data['upper_ci'] = calibration_data['actual_prob'] + 1.96 * calibration_data['se']\n",
    "    calibration_data['site']= site_name\n",
    "    \n",
    "    return calibration_data\n",
    "\n",
    "\n",
    "\n",
    "# Create calibration data with confidence intervals\n",
    "calibration_data = create_calibration_data(y_test, y_pred_proba)\n",
    "\n",
    "# Write the calibration data to a CSV file\n",
    "calibration_data.to_csv(f\"output/calibration_data_{site_name}.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Smooth the line using spline interpolation\n",
    "x_new = np.linspace(calibration_data['predicted_prob'].min(), calibration_data['predicted_prob'].max(), 300)\n",
    "spl = make_interp_spline(calibration_data['predicted_prob'], calibration_data['actual_prob'], k=3)\n",
    "y_smooth = spl(x_new)\n",
    "\n",
    "\n",
    "# Plot calibration plot with shaded confidence intervals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(calibration_data['predicted_prob'], \n",
    "                 calibration_data['lower_ci'], \n",
    "                 calibration_data['upper_ci'], \n",
    "                 color='green', alpha=0.2, label='95% CI')\n",
    "plt.plot(x_new, y_smooth, label='Calibration', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Actual Probability')\n",
    "plt.title('Calibration Plot with Confidence Intervals')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC & PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute Precision-Recall curve and AUC\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Ensure all arrays have the same length by matching dimensions correctly\n",
    "if len(fpr) != len(roc_thresholds):\n",
    "    roc_thresholds = np.append(roc_thresholds, 1)\n",
    "\n",
    "# Save values to CSV\n",
    "roc_data = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'roc_thresholds': roc_thresholds,'site':site_name})\n",
    "pr_data = pd.DataFrame({'precision': precision, 'recall': recall, 'pr_thresholds': np.append(pr_thresholds, 1),'site':site_name})\n",
    "\n",
    "roc_data.to_csv(f'output/roc_curve_data_{site_name}.csv', index=False)\n",
    "pr_data.to_csv(f'output/pr_curve_data_{site_name}.csv', index=False)\n",
    "\n",
    "# Plot ROC curve and PR curve in one image\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Plot PR curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall (PR) Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
